{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShiweiHe0713/Data-Science-for-Business-Techincal/blob/main/HW_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "mUbLmMW2quQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19350b2f-7405-4569-b449-ce6ef46a4190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DS4B_Sp24'...\n",
            "remote: Enumerating objects: 691, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 691 (delta 41), reused 92 (delta 41), pack-reused 598\u001b[K\n",
            "Receiving objects: 100% (691/691), 105.91 MiB | 27.18 MiB/s, done.\n",
            "Resolving deltas: 100% (304/304), done.\n",
            "Updating files: 100% (116/116), done.\n",
            "[Errno 20] Not a directory: 'DS4B_Sp24/Homeworks/HW_2.ipynb'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "#If opening in colab run this cell\n",
        "!git clone https://github.com/CTVisMe/DS4B_Sp24.git\n",
        "%cd DS4B_Sp24/Homeworks/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## # IF OPENING IN COLAB, REMEMBER TO SAVE THIS NOTEBOOK TO YOUR GOOGLE DRIVE!"
      ],
      "metadata": {
        "id": "QWx2G0Oc114C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjOdh8dhquQH"
      },
      "source": [
        "# HW2: Predicting Patient Show-Up\n",
        "\n",
        "The purpose of this part of the homework is to get you up to speed with data manipulation and model fitting using Python. These are the skills you will need to have for your term project.\n",
        "\n",
        "### Background\n",
        "\n",
        "You've been hired as the manager of Sacred Heart Medical Clinic (SHMC). As part of its business model, SHMC usually employs doctors on demand, meaning that doctors are asked to come only when there are appointments. However, once a doctor has been asked to come, you must pay him or her regardless of whether the patient shows up or not. You want to use data on previous appointments to figure out whether you can predict which patients are going to show up, so that you can plan better how many doctors to call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xYsbax8AquQI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the data containing past appointments (Remember to change this to the specific path of your data).\n",
        "data_path = \"./data/data-hw2.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbIMTbGFquQJ"
      },
      "source": [
        "### Loading the data\n",
        "\n",
        "**1. Load the data referenced by the path above into a pandas data frame. Print the total number of rows and columns, and show the first few rows in the dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "J3IyL_HPquQJ"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErywDcRSquQJ"
      },
      "source": [
        "Here's a brief summary of the variables you should see:\n",
        "\n",
        "1. PatientId - Identification of a patient.\n",
        "2. AppointmentID - Identification of each appointment.\n",
        "3. Gender - Male or female.\n",
        "4. ScheduledDay - The day someone called or registered the appointment.\n",
        "6. AppointmentDay - The day of the actual appointment, when the patient has to visit the doctor.\n",
        "7. Age = How old is the patient.\n",
        "8. Neighborhood - Place where the patient lives.\n",
        "9. Scholarship - Whether the patient receives financial help.\n",
        "10. Hypertension - Whether the patient suffers from hypertension.\n",
        "11. Diabetes - Whether the patient suffers from diabetes.\n",
        "12. Alcoholism - Whether the patient suffers from alcoholism.\n",
        "13. Handicap - Whether the patient is handicapped.\n",
        "14. SMS_received - Whether 1 or more SMS messages were sent to the patient\n",
        "15. No-show - Whether the patient missed the appointment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6hKBtJjquQK"
      },
      "source": [
        "**2. Check out if there are any Na or NaN values. If there are any, drop all the observations that include such values in any of the columns.** (This is not necessarily what you should do in your projects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zfyDXnazquQL"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6l4ZwVoquQL"
      },
      "source": [
        "### Dealing with dates\n",
        "\n",
        "**3. Transform ScheduledDay and AppointmentDay into datetimes (Hint: Use pandas for this).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bedKxs8AquQM"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iubdoGtHquQM"
      },
      "source": [
        "**4. If you take a look at both dates, you will see that ScheduledDay includes a specific time with the date, but AppointmentDay doesn't. In order to compare both fields more easily, apply \"normalize\" to ScheduledDay (i.e., keep only the dates). Hint: See the [normalize](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.dt.normalize.html) method.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MmgkKRlGquQM"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NYFhuCdquQN"
      },
      "source": [
        "**5. Create a new column called 'TimeInAdvance' for the difference in days between ScheduledDay and AppointmentDay. Make sure that the new field is numeric - and not of form \"TimeDelta\", which is the difference between two datetimes. (you can apply `dt.days`  to a datetime object to accomplish this).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tBZ93SUoquQN"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grm21af-quQN"
      },
      "source": [
        "There are many other features you may want to extract from date variables, such as the time at which the appointment was scheduled, the day of the week, the month, etc. However, we will only use TimeInAdvance for the purposes of this homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfz7DN2aquQO"
      },
      "source": [
        "### Cleaning data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjsdghivquQO"
      },
      "source": [
        "**6. Use the \"describe\" command from pandas to obtain some general stats about the data. Comment on any weird values you see in any of the columns? Remove all observations that include \"weird\" or otherwise questionable values and comment on why did you remove such observations. Also, print the number of observations you removed.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JkZEDSsbquQO"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTh2wUPDquQP"
      },
      "source": [
        "### Dealing with binary variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP4TFN9QquQP"
      },
      "source": [
        "**7. Create a new column called \"IsFemale\" that is 1 if the patient is female and 0 otherwise. Hint: Take a look at the [where](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.where.html) method. Make sure to also drop the Gender column.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uadx9djzquQP"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKskkHfrquQP"
      },
      "source": [
        "**8. Do the same for the No-show variable. It should be 1 if the person didn't show and 0 otherwise.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1sTT28XhquQQ"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po044eMAquQQ"
      },
      "source": [
        "### Dealing with categorical variables\n",
        "\n",
        "**9. Let's take a look at the Neighbordhood column. How many unique neighborhoods are there? Which are the 5 most common neighborhoods? Which are the 5 least common ones?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XlBA-cUWquQQ"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1wDioVkquQQ"
      },
      "source": [
        "**10. We often group together categories that are very rare because it's hard to generalize from them. Use .value_counts to find the total in each neighborhood.  Then, for the neighborhoods that appear less than 2000 times in the dataset replace their name with \"OTHER\". (Code provided below:)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "02fOXjpjquQQ"
      },
      "outputs": [],
      "source": [
        "## sample code - make sure to replace \"df\" with your data frame name if needed\n",
        "# counts = df['Neighborhood'].value_counts()\n",
        "# minor = counts[counts < 2000].index.tolist()\n",
        "# df.loc[df['Neighborhood'].isin(minor), 'Neighborhood'] = 'OTHER'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdOmVDnOquQR"
      },
      "source": [
        "**11. Get dummy/indicator variables for each neighborhood and add them to the dataframe. Hint: Take a look at the [get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) method (note - in class we discussed the need to create k-1 dummies if there are k categories when doing regression.  We do NOT have to do this with trees.  Tree models do not require creation of a baseline dummy variable - so you can use drop_first=False with `get_dummies`, which is the default.). Make sure to add the dummies to your data frame, and also drop the Neighborhood column once the dummies are created.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LDXvf6s4quQR"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5uVkHwoquQR"
      },
      "source": [
        "### Dealing with panel data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JdCMjTUquQR"
      },
      "source": [
        "There are many patients that have made more than one appointment. Panel data (also called longitudinal data) contain observations for the same individuals over multiple periods of time. In our particuclar case, such data may help us to make better predictions.\n",
        "\n",
        "For example, the fact that a patient has failed to show up in the past may be predictive of the patient not showing up in the future. We want to create a variable that calculates the number of no_shows BEFORE the current appointment..this is advanced so we give you the code to create this attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHhNkLiTquQR"
      },
      "source": [
        "**12. Create a new column called \"PreviousNoShows\" that for each appointment includes the number of past appointments to which the patient did not show. For example, if the person did not show to the first meeting, PreviousNoShows should be 0 for the first appointment and 1 for the second one (if there is any). (Code provided: Sort the dataframe by PatientID and ScheduledDay. Then, group by PatientID and compute the cumulative sum of the No-show variable)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HNG8kVFKquQS"
      },
      "outputs": [],
      "source": [
        "## sample code - make sure to replace \"df\" with your data frame name\n",
        "# df = df.sort_values(['PatientId', 'ScheduledDay'])\n",
        "# df['PreviousNoShows'] = df.groupby(['PatientId'])['No-show'].cumsum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uocC_E2MquQS"
      },
      "source": [
        "There are many other features we could compute with this data set, such as time between appointments, number of past appointments, fraction of appointments to which the patient did not show up, etc. However, for the purposes of this homework, we will only work with PreviousNoShows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOgI0n4KquQS"
      },
      "source": [
        "### Removing the unnecessary\n",
        "\n",
        "**13. Let's drop the columns we won't be needing. Drop PatientId, AppointmentID, ScheduledDay, AppointmentDay.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cOmTlUAYquQS"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncq5mqQPquQT"
      },
      "source": [
        "### Predictive modeling\n",
        "\n",
        "**14. Let's build a model to predict No-Show using a DecisionTreeClassifier. First, split the data into training and test (80/20) - using `random_state=123`.  Using max_depth=3, fit the DecisionTreeClassifier to the training set, and report the accuracy on the training set and the test set.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FHS_WvB5quQT"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoVO27AuquQT"
      },
      "source": [
        "**15. Now lets do 5-fold cross validation by calling cross_val_score with the FULL X and y data (the function does the splitting and fitting for us). Use the option `scoring=\"accuracy\"`.  Find the mean accuracy of the 5 numbers returned.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put your answer here"
      ],
      "metadata": {
        "id": "yH8XJgeTh0Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. Lets see what is the optimal depth for this tree. Create a for-loop that cycles over all max_depth values between 2 and 15 and prints out the mean cross-validated test accuracy for each value of max_depth.  Which value of max_depth has the highest cross-validated accuracy?**"
      ],
      "metadata": {
        "id": "xyZImqt_hd-r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "c2XTU5EUquQU"
      },
      "outputs": [],
      "source": [
        "# Put your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16b (Extra Credit) : Using the same for-loop, output for each level of max_depth the trainging accuracy, test accuracy, and cross_val accuracy.  Make a plot of depth(X-axis) vs accuracy(Y-axis) with three lines for (train, test, and cv) accuracy.   Interpret what you see.**\n"
      ],
      "metadata": {
        "id": "D226uunElfAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put your answer here"
      ],
      "metadata": {
        "id": "jLagFkjreppv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17.  Fit the tree model (again) using the optimal depth.  Create the 2x2 confusion matrix using the predictions on the test set, vs the true values of the test set (Y_test).**"
      ],
      "metadata": {
        "id": "Cbt3Gmanir7L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rFbOooOWeo2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put your answer here"
      ],
      "metadata": {
        "id": "p_9ECOgIjeEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. Use the functions `precision_score` and `recall_score` to calculate precision and recall - these numbers should correspond to the appropriate calculations from the 2x2 table.**"
      ],
      "metadata": {
        "id": "kQF32Bh_jf43"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05Z-Uo60jfjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18b.(Extra Credit - 2 points) The precision and recall above were calculated using a threshold of 0.5 (that is, any case with a probability over 0.5 is predicted as No-show).  As we discussed in class, changing the threshold will have an effect on precision and recall.  Change the threshold of labelling a No-show to 0.9 and re-calcuate precision and recall.  (you will need to generate a new 2x2 table and calculate P&R from the values in the table). Interpret the change in P&R between the two thresholds.**"
      ],
      "metadata": {
        "id": "ruuKAoPLkB4n"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}